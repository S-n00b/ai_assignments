<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Lenovo AAITC Team">
        <link rel="canonical" href="https://s-n00b.github.io/ai_assignments/TESTING/">
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Testing Guide for Lenovo AAITC Solutions - Lenovo AAITC Solutions</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/fontawesome.min.css" rel="stylesheet">
        <link href="../css/brands.min.css" rel="stylesheet">
        <link href="../css/solid.min.css" rel="stylesheet">
        <link href="../css/v4-font-face.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" >
        <link id="hljs-dark" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" disabled>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">Lenovo AAITC Solutions</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar-collapse" aria-controls="navbar-collapse" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="nav-item">
                                <a href=".." class="nav-link">Home</a>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Model Enablement & UX Evaluation</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../category1/ai-engineering-overview/" class="dropdown-item">AI Engineering Overview</a>
</li>
                                    
<li>
    <a href="../category1/model-evaluation-framework/" class="dropdown-item">Model Evaluation Framework</a>
</li>
                                    
<li>
    <a href="../category1/ux-evaluation-testing/" class="dropdown-item">UX Evaluation & Testing</a>
</li>
                                    
<li>
    <a href="../category1/model-profiling-characterization/" class="dropdown-item">Model Profiling & Characterization</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">AI System Architecture & MLOps</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../category2/system-architecture-overview/" class="dropdown-item">System Architecture Overview</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Executive Presentations</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../executive/carousel-slide-deck/" class="dropdown-item">Carousel Slide Deck</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Professional Skills & Insights</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../professional/executive-summary/" class="dropdown-item">Executive Summary</a>
</li>
                                    
<li>
    <a href="../professional/blog-posts/ai-architecture-seniority/" class="dropdown-item">AI Architecture Seniority</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item">
                                <a href="../live-applications/" class="nav-link">Live Applications</a>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Development</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../development/github-pages-setup/" class="dropdown-item">GitHub Pages Setup</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">Resources</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../resources/architecture/" class="dropdown-item">Architecture Diagrams</a>
</li>
                                    
<li>
    <a href="../resources/performance/" class="dropdown-item">Performance Metrics</a>
</li>
                                    
<li>
    <a href="../resources/troubleshooting/" class="dropdown-item">Troubleshooting</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a href="https://github.com/s-n00b/ai_assignments/edit/main/docs/TESTING.md" class="nav-link">Edit on s-n00b/ai_assignments
                                    </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-bs-level="1"><a href="#testing-guide-for-lenovo-aaitc-solutions" class="nav-link">Testing Guide for Lenovo AAITC Solutions</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#overview" class="nav-link">Overview</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#table-of-contents" class="nav-link">Table of Contents</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#testing-philosophy" class="nav-link">Testing Philosophy</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#test-structure" class="nav-link">Test Structure</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#running-tests" class="nav-link">Running Tests</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#test-categories" class="nav-link">Test Categories</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#writing-tests" class="nav-link">Writing Tests</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#test-data-and-fixtures" class="nav-link">Test Data and Fixtures</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#mocking-and-stubbing" class="nav-link">Mocking and Stubbing</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#performance-testing" class="nav-link">Performance Testing</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#cicd-integration" class="nav-link">CI/CD Integration</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#best-practices" class="nav-link">Best Practices</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#troubleshooting" class="nav-link">Troubleshooting</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#contributing" class="nav-link">Contributing</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#resources" class="nav-link">Resources</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="testing-guide-for-lenovo-aaitc-solutions">Testing Guide for Lenovo AAITC Solutions<a class="headerlink" href="#testing-guide-for-lenovo-aaitc-solutions" title="Permanent link">&para;</a></h1>
<h2 id="overview">Overview<a class="headerlink" href="#overview" title="Permanent link">&para;</a></h2>
<p>This document provides comprehensive guidance for testing the Lenovo AAITC Solutions project. The testing suite includes unit tests, integration tests, and end-to-end tests to ensure the reliability and quality of the AI model evaluation and architecture framework.</p>
<h2 id="table-of-contents">Table of Contents<a class="headerlink" href="#table-of-contents" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="#testing-philosophy">Testing Philosophy</a></li>
<li><a href="#test-structure">Test Structure</a></li>
<li><a href="#running-tests">Running Tests</a></li>
<li><a href="#test-categories">Test Categories</a></li>
<li><a href="#writing-tests">Writing Tests</a></li>
<li><a href="#test-data-and-fixtures">Test Data and Fixtures</a></li>
<li><a href="#mocking-and-stubbing">Mocking and Stubbing</a></li>
<li><a href="#performance-testing">Performance Testing</a></li>
<li><a href="#cicd-integration">CI/CD Integration</a></li>
<li><a href="#best-practices">Best Practices</a></li>
<li><a href="#troubleshooting">Troubleshooting</a></li>
</ul>
<h2 id="testing-philosophy">Testing Philosophy<a class="headerlink" href="#testing-philosophy" title="Permanent link">&para;</a></h2>
<p>Our testing approach follows these principles:</p>
<ol>
<li><strong>Comprehensive Coverage</strong>: Tests cover all major components and user scenarios</li>
<li><strong>Fast Feedback</strong>: Unit tests provide quick feedback during development</li>
<li><strong>Reliable Integration</strong>: Integration tests verify component interactions</li>
<li><strong>Real-world Scenarios</strong>: E2E tests validate complete user workflows</li>
<li><strong>Maintainable</strong>: Tests are well-organized, documented, and easy to maintain</li>
</ol>
<h2 id="test-structure">Test Structure<a class="headerlink" href="#test-structure" title="Permanent link">&para;</a></h2>
<pre><code>tests/
├── __init__.py
├── conftest.py                 # Shared fixtures and configuration
├── unit/                       # Unit tests for individual components
│   ├── test_model_evaluation.py
│   ├── test_ai_architecture.py
│   ├── test_gradio_app.py
│   └── test_utils.py
├── integration/                # Integration tests for component interactions
│   ├── test_model_evaluation_integration.py
│   ├── test_ai_architecture_integration.py
│   └── test_gradio_integration.py
├── e2e/                        # End-to-end tests for complete workflows
│   ├── test_complete_workflows.py
│   └── test_user_scenarios.py
└── fixtures/                   # Shared test fixtures and utilities
    ├── mock_objects.py
    └── test_data.py
</code></pre>
<h2 id="running-tests">Running Tests<a class="headerlink" href="#running-tests" title="Permanent link">&para;</a></h2>
<h3 id="prerequisites">Prerequisites<a class="headerlink" href="#prerequisites" title="Permanent link">&para;</a></h3>
<ol>
<li>Install dependencies:</li>
</ol>
<p><code>bash
   pip install -r config/requirements.txt</code></p>
<ol>
<li>Set up environment variables (for integration tests):
   <code>bash
   export OPENAI_API_KEY="your_key_here"
   export ANTHROPIC_API_KEY="your_key_here"</code></li>
</ol>
<h3 id="basic-test-commands">Basic Test Commands<a class="headerlink" href="#basic-test-commands" title="Permanent link">&para;</a></h3>
<pre><code class="language-bash"># Run all tests
pytest

# Run specific test categories
pytest tests/unit/              # Unit tests only
pytest tests/integration/       # Integration tests only
pytest tests/e2e/              # End-to-end tests only

# Run with coverage
pytest --cov=. --cov-report=html

# Run specific test files
pytest tests/unit/test_model_evaluation.py

# Run specific test methods
pytest tests/unit/test_model_evaluation.py::TestModelConfig::test_model_config_creation
</code></pre>
<h3 id="using-make-commands">Using Make Commands<a class="headerlink" href="#using-make-commands" title="Permanent link">&para;</a></h3>
<pre><code class="language-bash"># Quick commands
make test                      # Run all tests
make test-unit                 # Unit tests only
make test-integration          # Integration tests only
make test-e2e                  # End-to-end tests only
make test-all                  # All tests with coverage

# Development commands
make lint                      # Run linting checks
make format                    # Format code
make security                  # Run security checks
make clean                     # Clean up generated files
</code></pre>
<h2 id="test-categories">Test Categories<a class="headerlink" href="#test-categories" title="Permanent link">&para;</a></h2>
<h3 id="unit-tests">Unit Tests<a class="headerlink" href="#unit-tests" title="Permanent link">&para;</a></h3>
<p>Unit tests verify individual components in isolation:</p>
<ul>
<li><strong>Model Evaluation</strong>: Configuration, pipeline, robustness testing, bias detection</li>
<li><strong>AI Architecture</strong>: Platform, lifecycle management, agents, RAG systems</li>
<li><strong>Gradio App</strong>: Interfaces, components, MCP server integration</li>
<li><strong>Utils</strong>: Logging, visualization, data processing, configuration</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-python">def test_model_config_creation():
    &quot;&quot;&quot;Test basic model configuration creation.&quot;&quot;&quot;
    config = ModelConfig(
        model_name=&quot;gpt-3.5-turbo&quot;,
        model_version=&quot;2024-01-01&quot;,
        api_key=&quot;test-key&quot;
    )

    assert config.model_name == &quot;gpt-3.5-turbo&quot;
    assert config.max_tokens == 1000  # default value
</code></pre>
<h3 id="integration-tests">Integration Tests<a class="headerlink" href="#integration-tests" title="Permanent link">&para;</a></h3>
<p>Integration tests verify component interactions:</p>
<ul>
<li><strong>Model Evaluation Integration</strong>: Pipeline with robustness and bias detection</li>
<li><strong>AI Architecture Integration</strong>: Platform with lifecycle management and agents</li>
<li><strong>Gradio Integration</strong>: Frontend with backend systems</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-python">@pytest.mark.asyncio
async def test_complete_evaluation_workflow():
    &quot;&quot;&quot;Test complete evaluation workflow integration.&quot;&quot;&quot;
    pipeline = ComprehensiveEvaluationPipeline(...)
    robustness_suite = RobustnessTestingSuite(...)

    # Test integrated workflow
    results = await pipeline.evaluate_all_models(test_data)
    assert &quot;robustness&quot; in results[0]
</code></pre>
<h3 id="end-to-end-tests">End-to-End Tests<a class="headerlink" href="#end-to-end-tests" title="Permanent link">&para;</a></h3>
<p>E2E tests validate complete user workflows:</p>
<ul>
<li><strong>Complete Workflows</strong>: Model evaluation, AI architecture, MLOps, RAG systems</li>
<li><strong>User Scenarios</strong>: Data scientist, ML engineer, business user perspectives</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-python">@pytest.mark.asyncio
async def test_data_scientist_model_comparison_scenario():
    &quot;&quot;&quot;Test data scientist comparing multiple models.&quot;&quot;&quot;
    # Step 1: User logs in
    # Step 2: Selects models
    # Step 3: Configures evaluation
    # Step 4: Runs evaluation
    # Step 5: Analyzes results
    # Step 6: Generates report
</code></pre>
<h2 id="writing-tests">Writing Tests<a class="headerlink" href="#writing-tests" title="Permanent link">&para;</a></h2>
<h3 id="test-naming-conventions">Test Naming Conventions<a class="headerlink" href="#test-naming-conventions" title="Permanent link">&para;</a></h3>
<ul>
<li>Test files: <code>test_*.py</code></li>
<li>Test classes: <code>Test*</code></li>
<li>Test methods: <code>test_*</code></li>
<li>Descriptive names that explain what is being tested</li>
</ul>
<h3 id="test-structure_1">Test Structure<a class="headerlink" href="#test-structure_1" title="Permanent link">&para;</a></h3>
<pre><code class="language-python">class TestComponentName:
    &quot;&quot;&quot;Test cases for ComponentName class.&quot;&quot;&quot;

    @pytest.fixture
    def component(self):
        &quot;&quot;&quot;Create component instance for testing.&quot;&quot;&quot;
        return ComponentName()

    def test_basic_functionality(self, component):
        &quot;&quot;&quot;Test basic component functionality.&quot;&quot;&quot;
        # Arrange
        input_data = &quot;test_input&quot;

        # Act
        result = component.process(input_data)

        # Assert
        assert result == &quot;expected_output&quot;

    @pytest.mark.asyncio
    async def test_async_functionality(self, component):
        &quot;&quot;&quot;Test async component functionality.&quot;&quot;&quot;
        result = await component.async_process(&quot;test_input&quot;)
        assert result is not None
</code></pre>
<h3 id="test-markers">Test Markers<a class="headerlink" href="#test-markers" title="Permanent link">&para;</a></h3>
<p>Use pytest markers to categorize tests:</p>
<pre><code class="language-python">@pytest.mark.unit
def test_unit_functionality():
    pass

@pytest.mark.integration
def test_integration_functionality():
    pass

@pytest.mark.e2e
def test_e2e_functionality():
    pass

@pytest.mark.slow
def test_slow_functionality():
    pass

@pytest.mark.api
def test_api_functionality():
    pass
</code></pre>
<h2 id="test-data-and-fixtures">Test Data and Fixtures<a class="headerlink" href="#test-data-and-fixtures" title="Permanent link">&para;</a></h2>
<h3 id="using-fixtures">Using Fixtures<a class="headerlink" href="#using-fixtures" title="Permanent link">&para;</a></h3>
<p>Fixtures provide reusable test data and setup:</p>
<pre><code class="language-python">@pytest.fixture
def sample_model_config():
    &quot;&quot;&quot;Sample model configuration for testing.&quot;&quot;&quot;
    return ModelConfig(
        model_name=&quot;gpt-3.5-turbo&quot;,
        api_key=&quot;test-key&quot;
    )

def test_with_fixture(sample_model_config):
    assert sample_model_config.model_name == &quot;gpt-3.5-turbo&quot;
</code></pre>
<h3 id="test-data-files">Test Data Files<a class="headerlink" href="#test-data-files" title="Permanent link">&para;</a></h3>
<p>Sample data is provided in <code>tests/fixtures/test_data.py</code>:</p>
<ul>
<li><code>sample_evaluation_dataset</code>: Test prompts and expected outputs</li>
<li><code>sample_bias_test_dataset</code>: Bias testing data</li>
<li><code>sample_robustness_test_dataset</code>: Robustness testing data</li>
<li><code>sample_model_configurations</code>: Model configurations</li>
<li><code>sample_architecture_configurations</code>: Architecture configurations</li>
</ul>
<h2 id="mocking-and-stubbing">Mocking and Stubbing<a class="headerlink" href="#mocking-and-stubbing" title="Permanent link">&para;</a></h2>
<h3 id="mock-objects">Mock Objects<a class="headerlink" href="#mock-objects" title="Permanent link">&para;</a></h3>
<p>Use mock objects to isolate components:</p>
<pre><code class="language-python">from unittest.mock import Mock, patch, AsyncMock

def test_with_mock():
    mock_client = Mock()
    mock_client.generate.return_value = {&quot;response&quot;: &quot;test&quot;}

    with patch('module.api_client', mock_client):
        result = module.call_api()
        assert result == &quot;test&quot;
</code></pre>
<h3 id="async-mocking">Async Mocking<a class="headerlink" href="#async-mocking" title="Permanent link">&para;</a></h3>
<p>For async functions, use <code>AsyncMock</code>:</p>
<pre><code class="language-python">@pytest.mark.asyncio
async def test_async_with_mock():
    mock_client = AsyncMock()
    mock_client.generate.return_value = {&quot;response&quot;: &quot;test&quot;}

    with patch('module.async_client', mock_client):
        result = await module.async_call_api()
        assert result == &quot;test&quot;
</code></pre>
<h2 id="performance-testing">Performance Testing<a class="headerlink" href="#performance-testing" title="Permanent link">&para;</a></h2>
<h3 id="benchmarking">Benchmarking<a class="headerlink" href="#benchmarking" title="Permanent link">&para;</a></h3>
<p>Use pytest-benchmark for performance testing:</p>
<pre><code class="language-python">def test_performance(benchmark):
    result = benchmark(expensive_function, large_dataset)
    assert result is not None
</code></pre>
<h3 id="performance-baselines">Performance Baselines<a class="headerlink" href="#performance-baselines" title="Permanent link">&para;</a></h3>
<p>Run benchmarks to establish baselines:</p>
<pre><code class="language-bash">pytest --benchmark-only --benchmark-save=baseline
</code></pre>
<p>Compare against baselines:</p>
<pre><code class="language-bash">pytest --benchmark-compare=baseline
</code></pre>
<h2 id="cicd-integration">CI/CD Integration<a class="headerlink" href="#cicd-integration" title="Permanent link">&para;</a></h2>
<h3 id="github-actions">GitHub Actions<a class="headerlink" href="#github-actions" title="Permanent link">&para;</a></h3>
<p>Tests run automatically on:</p>
<ul>
<li>Push to main/develop branches</li>
<li>Pull requests</li>
<li>Daily scheduled runs</li>
</ul>
<h3 id="test-reports">Test Reports<a class="headerlink" href="#test-reports" title="Permanent link">&para;</a></h3>
<p>CI generates:</p>
<ul>
<li>Unit test results</li>
<li>Integration test results</li>
<li>E2E test results</li>
<li>Coverage reports</li>
<li>Security scan results</li>
<li>Performance benchmarks</li>
</ul>
<h3 id="local-ci-simulation">Local CI Simulation<a class="headerlink" href="#local-ci-simulation" title="Permanent link">&para;</a></h3>
<p>Run CI checks locally:</p>
<pre><code class="language-bash">make ci-test      # Run all tests
make ci-lint      # Run linting
make ci-security  # Run security checks
</code></pre>
<h2 id="best-practices">Best Practices<a class="headerlink" href="#best-practices" title="Permanent link">&para;</a></h2>
<h3 id="test-organization">Test Organization<a class="headerlink" href="#test-organization" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>One test per concept</strong>: Each test should verify one specific behavior</li>
<li><strong>Descriptive names</strong>: Test names should clearly describe what is being tested</li>
<li><strong>Arrange-Act-Assert</strong>: Structure tests with clear setup, execution, and verification</li>
<li><strong>Independent tests</strong>: Tests should not depend on each other</li>
</ol>
<h3 id="test-data">Test Data<a class="headerlink" href="#test-data" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Use fixtures</strong>: Reuse common test data through fixtures</li>
<li><strong>Minimal data</strong>: Use the smallest dataset that tests the functionality</li>
<li><strong>Realistic data</strong>: Use data that represents real-world scenarios</li>
<li><strong>Clean data</strong>: Ensure test data is consistent and predictable</li>
</ol>
<h3 id="error-handling">Error Handling<a class="headerlink" href="#error-handling" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Test error cases</strong>: Verify that errors are handled correctly</li>
<li><strong>Test edge cases</strong>: Include boundary conditions and edge cases</li>
<li><strong>Test validation</strong>: Verify input validation and error messages</li>
</ol>
<h3 id="async-testing">Async Testing<a class="headerlink" href="#async-testing" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Use pytest-asyncio</strong>: Mark async tests with <code>@pytest.mark.asyncio</code></li>
<li><strong>Mock async dependencies</strong>: Use <code>AsyncMock</code> for async dependencies</li>
<li><strong>Test timeouts</strong>: Include timeout handling in async tests</li>
</ol>
<h2 id="troubleshooting">Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permanent link">&para;</a></h2>
<h3 id="common-issues">Common Issues<a class="headerlink" href="#common-issues" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Import Errors</strong>: Ensure all dependencies are installed</li>
<li><strong>Async Test Failures</strong>: Check that async tests are properly marked</li>
<li><strong>Mock Issues</strong>: Verify mock objects are properly configured</li>
<li><strong>Timeout Errors</strong>: Increase timeout for slow tests</li>
</ol>
<h3 id="debug-commands">Debug Commands<a class="headerlink" href="#debug-commands" title="Permanent link">&para;</a></h3>
<pre><code class="language-bash"># Run tests with verbose output
pytest -v -s

# Run specific test with debugging
pytest tests/unit/test_model_evaluation.py::TestModelConfig::test_model_config_creation -v -s

# Run tests with coverage and show missing lines
pytest --cov=. --cov-report=term-missing

# Run tests and stop on first failure
pytest -x

# Run tests with maximum failures
pytest --maxfail=3
</code></pre>
<h3 id="test-environment">Test Environment<a class="headerlink" href="#test-environment" title="Permanent link">&para;</a></h3>
<p>Ensure your test environment matches CI:</p>
<pre><code class="language-bash"># Use same Python version as CI
python --version

# Install exact dependencies
pip install -r config/requirements.txt

# Set environment variables
export PYTHONPATH=$PWD
</code></pre>
<h2 id="contributing">Contributing<a class="headerlink" href="#contributing" title="Permanent link">&para;</a></h2>
<p>When adding new tests:</p>
<ol>
<li>Follow the existing test structure and naming conventions</li>
<li>Add appropriate test markers</li>
<li>Include docstrings explaining what is being tested</li>
<li>Use fixtures for common test data</li>
<li>Mock external dependencies</li>
<li>Ensure tests are fast and reliable</li>
<li>Update this documentation if needed</li>
</ol>
<h2 id="resources">Resources<a class="headerlink" href="#resources" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="https://docs.pytest.org/">pytest Documentation</a></li>
<li><a href="https://pytest-asyncio.readthedocs.io/">pytest-asyncio Documentation</a></li>
<li><a href="https://docs.python.org/3/library/unittest.mock.html">unittest.mock Documentation</a></li>
<li><a href="https://pytest-benchmark.readthedocs.io/">pytest-benchmark Documentation</a></li>
<li><a href="https://coverage.readthedocs.io/">Coverage.py Documentation</a></li>
</ul></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2025 Lenovo AAITC Team</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../js/bootstrap.bundle.min.js"></script>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js"></script>
        <script src="../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
